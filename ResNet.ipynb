{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import os\n",
    "import path\n",
    "import pydot\n",
    "from typing import List, Tuple\n",
    "from matplotlib.pyplot import imshow\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import PIL.Image\n",
    "import pathlib\n",
    "import shutil\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D\n",
    "from tensorflow.keras.initializers import glorot_uniform\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "\n",
    "from tensorflow.python.keras.utils import layer_utils\n",
    "#from tensorflow.keras.utils.vis_utils import model_to_dot\n",
    "from tensorflow.keras.utils import model_to_dot\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "from tensorflow.keras.applications.imagenet_utils import preprocess_input\n",
    "\n",
    "from IPython.display import SVG\n",
    "\n",
    "import scipy.misc\n",
    "\n",
    "import tensorflow.keras.backend as K\n",
    "K.set_image_data_format('channels_last') # can be channels_first or channels_last. \n",
    "K.set_learning_phase(1) # 1 stands for learning phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identity_block(X: tf.Tensor, level: int, block: int, filters: List[int]) -> tf.Tensor:\n",
    "    \"\"\"\n",
    "    Creates an identity block (see figure 3.1 from readme)\n",
    "\n",
    "    Input:\n",
    "        X - input tensor of shape (m, height_prev, width_prev, chan_prev)\n",
    "        level - integer, one of the 5 levels that our networks is conceptually divided into (see figure 3.1 in the readme file)\n",
    "              - level names have the form: conv2_x, conv3_x ... conv5_x\n",
    "        block - each conceptual level has multiple blocks (1 identity and several convolutional blocks)\n",
    "                block is the number of this block within its conceptual layer\n",
    "                i.e. first block from level 2 will be named conv2_1\n",
    "        filters - a list on integers, each of them defining the number of filters in each convolutional layer\n",
    "\n",
    "    Output:\n",
    "        X - tensor (m, height, width, chan)\n",
    "    \"\"\"\n",
    "\n",
    "    # layers will be called conv{level}_iden{block}_{convlayer_number_within_block}'\n",
    "    conv_name = f'conv{level}_{block}' + '_{layer}_{type}'\n",
    "\n",
    "    # unpack number of filters to be used for each conv layer\n",
    "    f1, f2, f3 = filters\n",
    "\n",
    "    # the shortcut branch of the identity block\n",
    "    # takes the value of the block input\n",
    "    X_shortcut = X\n",
    "\n",
    "    # first convolutional layer (plus batch norm & relu activation, of course)\n",
    "    X = Conv2D(filters=f1, kernel_size=(1, 1), strides=(1, 1),\n",
    "               padding='valid', name=conv_name.format(layer=1, type='conv'),\n",
    "               kernel_initializer=glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis=3, name=conv_name.format(layer=1, type='bn'))(X)\n",
    "    X = Activation('relu', name=conv_name.format(layer=1, type='relu'))(X)\n",
    "\n",
    "    # second convolutional layer\n",
    "    X = Conv2D(filters=f2, kernel_size=(3, 3), strides=(1, 1),\n",
    "               padding='same', name=conv_name.format(layer=2, type='conv'),\n",
    "               kernel_initializer=glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis=3, name=conv_name.format(layer=2, type='bn'))(X)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    # third convolutional layer\n",
    "    X = Conv2D(filters=f3, kernel_size=(1, 1), strides=(1, 1),\n",
    "               padding='valid', name=conv_name.format(layer=3, type='conv'),\n",
    "               kernel_initializer=glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis=3, name=conv_name.format(layer=3, type='bn'))(X)\n",
    "\n",
    "    # add shortcut branch to main path\n",
    "    X = Add()([X, X_shortcut])\n",
    "\n",
    "    # relu activation at the end of the block\n",
    "    X = Activation('relu', name=conv_name.format(layer=3, type='relu'))(X)\n",
    "\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolutional_block(X: tf.Tensor, level: int, block: int, filters: List[int], s: Tuple[int,int,int]=(2, 2)) -> tf.Tensor:\n",
    "    \"\"\"\n",
    "    Creates a convolutional block (see figure 3.1 from readme)\n",
    "\n",
    "    Input:\n",
    "        X - input tensor of shape (m, height_prev, width_prev, chan_prev)\n",
    "        level - integer, one of the 5 levels that our networks is conceptually divided into (see figure 3.1 in the readme file)\n",
    "              - level names have the form: conv2_x, conv3_x ... conv5_x\n",
    "        block - each conceptual level has multiple blocks (1 identity and several convolutional blocks)\n",
    "                block is the number of this block within its conceptual layer\n",
    "                i.e. first block from level 2 will be named conv2_1\n",
    "        filters - a list on integers, each of them defining the number of filters in each convolutional layer\n",
    "        s   - stride of the first layer;\n",
    "            - a conv layer with a filter that has a stride of 2 will reduce the width and height of its input by half\n",
    "\n",
    "    Output:\n",
    "        X - tensor (m, height, width, chan)\n",
    "    \"\"\"\n",
    "\n",
    "    # layers will be called conv{level}_{block}_{convlayer_number_within_block}'\n",
    "    conv_name = f'conv{level}_{block}' + '_{layer}_{type}'\n",
    "\n",
    "    # unpack number of filters to be used for each conv layer\n",
    "    f1, f2, f3 = filters\n",
    "\n",
    "    # the shortcut branch of the convolutional block\n",
    "    X_shortcut = X\n",
    "\n",
    "    # first convolutional layer\n",
    "    X = Conv2D(filters=f1, kernel_size=(1, 1), strides=s, padding='valid',\n",
    "               name=conv_name.format(layer=1, type='conv'),\n",
    "               kernel_initializer=glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis=3, name=conv_name.format(layer=1, type='bn'))(X)\n",
    "    X = Activation('relu', name=conv_name.format(layer=1, type='relu'))(X)\n",
    "\n",
    "    # second convolutional layer\n",
    "    X = Conv2D(filters=f2, kernel_size=(3, 3), strides=(1, 1), padding='same',\n",
    "               name=conv_name.format(layer=2, type='conv'),\n",
    "               kernel_initializer=glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis=3, name=conv_name.format(layer=2, type='bn'))(X)\n",
    "    X = Activation('relu', name=conv_name.format(layer=2, type='relu'))(X)\n",
    "\n",
    "    # third convolutional layer\n",
    "    X = Conv2D(filters=f3, kernel_size=(1, 1), strides=(1, 1), padding='valid',\n",
    "               name=conv_name.format(layer=3, type='conv'),\n",
    "               kernel_initializer=glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis=3, name=conv_name.format(layer=3, type='bn'))(X)\n",
    "\n",
    "    # shortcut path\n",
    "    X_shortcut = Conv2D(filters=f3, kernel_size=(1, 1), strides=s, padding='valid',\n",
    "                        name=conv_name.format(layer='short', type='conv'),\n",
    "                        kernel_initializer=glorot_uniform(seed=0))(X_shortcut)\n",
    "    X_shortcut = BatchNormalization(axis=3, name=conv_name.format(layer='short', type='bn'))(X_shortcut)\n",
    "\n",
    "    # add shortcut branch to main path\n",
    "    X = Add()([X, X_shortcut])\n",
    "\n",
    "    # nonlinearity\n",
    "    X = Activation('relu', name=conv_name.format(layer=3, type='relu'))(X)\n",
    "\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ResNet50(input_size: Tuple[int,int,int], classes: int) -> Model:\n",
    "    \"\"\"\n",
    "        Builds the ResNet50 model (see figure 4.2 from readme)\n",
    "\n",
    "        Input:\n",
    "            - input_size - a (height, width, chan) tuple, the shape of the input images\n",
    "            - classes - number of classes the model must learn\n",
    "\n",
    "        Output:\n",
    "            model - a Keras Model() instance\n",
    "    \"\"\"\n",
    "\n",
    "    # tensor placeholder for the model's input\n",
    "    X_input = Input(input_size)\n",
    "\n",
    "    ### Level 1 ###\n",
    "\n",
    "    # padding\n",
    "    X = ZeroPadding2D((3, 3))(X_input)\n",
    "\n",
    "    # convolutional layer, followed by batch normalization and relu activation\n",
    "    X = Conv2D(filters=64, kernel_size=(7, 7), strides=(2, 2),\n",
    "               name='conv1_1_1_conv',\n",
    "               kernel_initializer=glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis=3, name='conv1_1_1_nb')(X)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    ### Level 2 ###\n",
    "\n",
    "    # max pooling layer to halve the size coming from the previous layer\n",
    "    X = MaxPooling2D((3, 3), strides=(2, 2))(X)\n",
    "\n",
    "    # 1x convolutional block\n",
    "    X = convolutional_block(X, level=2, block=1, filters=[64, 64, 256], s=(1, 1))\n",
    "\n",
    "    # 2x identity blocks\n",
    "    X = identity_block(X, level=2, block=2, filters=[64, 64, 256])\n",
    "    X = identity_block(X, level=2, block=3, filters=[64, 64, 256])\n",
    "\n",
    "    ### Level 3 ###\n",
    "\n",
    "    # 1x convolutional block\n",
    "    X = convolutional_block(X, level=3, block=1, filters=[128, 128, 512], s=(2, 2))\n",
    "\n",
    "    # 3x identity blocks\n",
    "    X = identity_block(X, level=3, block=2, filters=[128, 128, 512])\n",
    "    X = identity_block(X, level=3, block=3, filters=[128, 128, 512])\n",
    "    X = identity_block(X, level=3, block=4, filters=[128, 128, 512])\n",
    "\n",
    "    ### Level 4 ###\n",
    "    # 1x convolutional block\n",
    "    X = convolutional_block(X, level=4, block=1, filters=[256, 256, 1024], s=(2, 2))\n",
    "    # 5x identity blocks\n",
    "    X = identity_block(X, level=4, block=2, filters=[256, 256, 1024])\n",
    "    X = identity_block(X, level=4, block=3, filters=[256, 256, 1024])\n",
    "    X = identity_block(X, level=4, block=4, filters=[256, 256, 1024])\n",
    "    X = identity_block(X, level=4, block=5, filters=[256, 256, 1024])\n",
    "    X = identity_block(X, level=4, block=6, filters=[256, 256, 1024])\n",
    "\n",
    "    ### Level 5 ###\n",
    "    # 1x convolutional block\n",
    "    X = convolutional_block(X, level=5, block=1, filters=[512, 512, 2048], s=(2, 2))\n",
    "    # 2x identity blocks\n",
    "    X = identity_block(X, level=5, block=2, filters=[512, 512, 2048])\n",
    "    X = identity_block(X, level=5, block=3, filters=[512, 512, 2048])\n",
    "\n",
    "    # Pooling layers\n",
    "    X = AveragePooling2D(pool_size=(2, 2), name='avg_pool')(X)\n",
    "\n",
    "    # Output layer\n",
    "    X = Flatten()(X)\n",
    "    X = Dense(classes, activation='softmax', name='fc_' + str(classes),\n",
    "              kernel_initializer=glorot_uniform(seed=0))(X)\n",
    "\n",
    "    # Create model\n",
    "    model = Model(inputs=X_input, outputs=X, name='ResNet50')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set input image parameters\n",
    "image_size = (64, 64) \n",
    "channels = 3\n",
    "num_classes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNet50(input_size = (image_size[1], image_size[0], channels), classes = num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to desired image set, relative to current working dir\n",
    "in_folder = os.path.join('.', 'input')\n",
    "\n",
    "file_count = []\n",
    "\n",
    "# get number of images in each folder (images per class)\n",
    "for fld in os.listdir(in_folder):\n",
    "    crt = os.path.join(in_folder, fld)\n",
    "    \n",
    "    image_count = len(os.listdir(crt))\n",
    "    \n",
    "    file_count.append(image_count)\n",
    "    \n",
    "    print(f'{crt} contains {image_count} images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Total number of images: {sum(file_count)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir(os.path.join(in_folder, 'elefante'))[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\\output\\animals10\\processed\n"
     ]
    }
   ],
   "source": [
    "out_folder = os.path.join('.', 'output')\n",
    "print(out_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def square_crop_image(im: PIL.Image) -> PIL.Image:\n",
    "    width, height = im.size\n",
    "    new_size = min(width, height)\n",
    "\n",
    "    # center crop\n",
    "    left = (width - new_size) / 2\n",
    "    top = (height - new_size) / 2\n",
    "    right = (width + new_size) / 2\n",
    "    bottom = (height + new_size) / 2\n",
    "\n",
    "    crop_im = im.crop((left, top, right, bottom))\n",
    "    crop_im = crop_im.convert('RGB')\n",
    "\n",
    "    return crop_im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataset(in_folder, im_per_class):\n",
    "    # iterate through all folders (there should be one folder per object class)\n",
    "    for fld in os.listdir(in_folder):\n",
    "        # create the output folder for processed images for current class\n",
    "        # delete folder and contents if there is one already\n",
    "        out = os.path.join(out_folder, fld)\n",
    "        if os.path.exists(out):\n",
    "            shutil.rmtree(out)\n",
    "        os.makedirs(out)\n",
    "\n",
    "        fld_path = pathlib.Path(os.path.join(in_folder, fld))\n",
    "        num_images = 0\n",
    "        for file in list(fld_path.glob('*')):\n",
    "            # open image, center crop to a square\n",
    "            # save to the output folder\n",
    "            try:\n",
    "                with PIL.Image.open(file) as im:\n",
    "                    crop_im = square_crop_image(im)\n",
    "                    crop_im.save(os.path.join(out, str(num_images) + '.jpg'))\n",
    "                    im.close()\n",
    "                # break when desired number of images\n",
    "                # has been processed (to keep classes balance)\n",
    "                num_images = num_images + 1\n",
    "                if (num_images > im_per_class):\n",
    "                    break\n",
    "            except:\n",
    "                print(f'Error processing {file}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the number of images that will make our classes balanced\n",
    "im_per_class = min(file_count)\n",
    "\n",
    "# process input images \n",
    "make_dataset(in_folder, im_per_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_height = image_size[1]\n",
    "img_width = image_size[0]\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = pathlib.Path(out_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    data_dir,\n",
    "    validation_split = 0.2,\n",
    "    subset=\"training\",\n",
    "    label_mode='categorical', # default mode is 'int' label, but we want one-hot encoded labels (e.g. for categorical_crossentropy loss)\n",
    "    seed=123,\n",
    "    image_size=(img_height, img_width),\n",
    "    batch_size=batch_size\n",
    ")\n",
    "\n",
    "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    data_dir,\n",
    "    validation_split=0.2,\n",
    "    subset=\"validation\",\n",
    "    label_mode='categorical',\n",
    "    seed=123,\n",
    "    image_size=(img_height, img_width),\n",
    "    batch_size=batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = train_ds.class_names\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "\n",
    "i = 1\n",
    "\n",
    "for images, labels in train_ds.take(1):\n",
    "    for (image, label) in zip(images, labels): \n",
    "        ax = plt.subplot(4, 4, i)\n",
    "        plt.imshow(image.numpy().astype(\"uint8\"))\n",
    "        plt.title(class_names[tf.argmax(label, axis=0)])\n",
    "        plt.axis(\"off\")\n",
    "        i = i + 1\n",
    "        if i == 17:\n",
    "            break\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use keras functionality for adding a rescaling layer\n",
    "normalization_layer = layers.experimental.preprocessing.Rescaling(1./255)\n",
    "\n",
    "# rescale training and validation sets\n",
    "norm_train_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))\n",
    "norm_val_ds = val_ds.map(lambda x, y: (normalization_layer(x), y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_batch, labels_batch = next(iter(norm_train_ds))\n",
    "\n",
    "# get one image\n",
    "first_image = image_batch[0]\n",
    "\n",
    "# confirm pixel values are now in the [0,1] range\n",
    "print(np.min(first_image), np.max(first_image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer='adam', # optimizer\n",
    "    loss='categorical_crossentropy', # loss function to optimize \n",
    "    metrics=['accuracy'] # metrics to monitor\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "norm_train_ds = norm_train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "norm_val_ds = norm_val_ds.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "model.fit(\n",
    "    norm_train_ds, \n",
    "    validation_data=norm_val_ds,\n",
    "    epochs = 2)\n",
    "\n",
    "stop = time.time()\n",
    "\n",
    "print(f'Training took: {(stop-start)/60} minutes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
